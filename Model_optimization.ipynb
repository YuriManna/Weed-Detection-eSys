{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e39c17bc",
   "metadata": {},
   "source": [
    "## Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1a5607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using half precision\n",
    "model_fp32 = onnx.load(\"models\\\\trained_yolov8m.onnx\")\n",
    "print(\"\\nConverting to half precision...\")\n",
    "model_fp16 = float16.convert_float_to_float16(model_fp32)\n",
    "onnx.save(model_fp16, \"models\\\\fp16_yolov8m.onnx\")\n",
    "print(f\"Exported model saved to: models\\\\fp16_yolov8m.onnx\")\n",
    "size_mb = os.path.getsize(\"models\\\\fp16_yolov8m.onnx\") / (1024 * 1024)\n",
    "print(f\"Model size: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c277ecd",
   "metadata": {},
   "source": [
    "### Integer quantization\n",
    "Following the steps of https://medium.com/@sulavstha007/quantizing-yolo-v8-models-34c39a2c10e2 static quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a24755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Quantization currently not done\n",
    "\n",
    "# to preprocess the model\n",
    "!python -m onnxruntime.quantization.preprocess --input \"models\\\\trained_yolov8m.onnx\" --output \"models\\preprocessed.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8316cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from onnxruntime.quantization import CalibrationDataReader, quantize_static, QuantType, QuantFormat\n",
    "    \n",
    "# Class for Callibration Data reading\n",
    "class ImageCalibrationDataReader(CalibrationDataReader):\n",
    "    def __init__(self, image_paths):\n",
    "        self.image_paths = image_paths\n",
    "        self.idx = 0\n",
    "        self.input_name = \"images\"\n",
    "\n",
    "    def get_next(self):\n",
    "        # method to iterate through the data set\n",
    "        if self.idx >= len(self.image_paths):\n",
    "            return None\n",
    "\n",
    "        image_path = self.image_paths[self.idx]\n",
    "        input_data = self.preprocess(image_path)\n",
    "        self.idx += 1\n",
    "        return {self.input_name: input_data}\n",
    "\n",
    "# Assuming you have a list of image paths for calibration\n",
    "calibration_image_paths = ['datasets\\yolo_CropOrWeed2\\images\\val\\ave-0035-0002.jpg',\"datasets\\yolo_CropOrWeed2\\images\\val\\ave-0035-0006.jpg\",\"datasets\\yolo_CropOrWeed2\\images\\val\\ave-0035-0007.jpg\"] # you can add more of the image paths\n",
    "\n",
    "# Create an instance of the ImageCalibrationDataReader\n",
    "calibration_data_reader = ImageCalibrationDataReader(calibration_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb78934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the calibration_data_reader with quantize_static\n",
    "# TODO which nodes to exclude?\n",
    "quantize_static('preprocessed.onnx', \"static_quantized.onnx\",\n",
    "                weight_type=QuantType.QInt8,\n",
    "                activation_type=QuantType.QUInt8,\n",
    "                calibration_data_reader=calibration_data_reader,\n",
    "                quant_format=QuantFormat.QDQ,\n",
    "                nodes_to_exclude=['/model.22/Concat_3', '/model.22/Split', '/model.22/Sigmoid'\n",
    "                                 '/model.22/dfl/Reshape', '/model.22/dfl/Transpose', '/model.22/dfl/Softmax', \n",
    "                                 '/model.22/dfl/conv/Conv', '/model.22/dfl/Reshape_1', '/model.22/Slice_1',\n",
    "                                 '/model.22/Slice', '/model.22/Add_1', '/model.22/Sub', '/model.22/Div_1',\n",
    "                                  '/model.22/Concat_4', '/model.22/Mul_2', '/model.22/Concat_5'],\n",
    "                per_channel=False,\n",
    "                reduce_range=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ddda2d",
   "metadata": {},
   "source": [
    "## Pruning (graph based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f2ed94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from ultralytics import YOLO, __version__\n",
    "from ultralytics.nn.modules import Detect, C2f, Conv, Bottleneck, C2fCIB, RepVGGDW, Concat, PSA, Attention, C3k2, C3k, CIB\n",
    "from ultralytics.nn.tasks import attempt_load_one_weight\n",
    "from ultralytics.engine.model import TASK2DATA\n",
    "from ultralytics.engine.trainer import BaseTrainer\n",
    "from ultralytics.utils import yaml_load, LOGGER, RANK, DEFAULT_CFG_DICT, DEFAULT_CFG_KEYS\n",
    "from ultralytics.utils.checks import check_yaml\n",
    "from ultralytics.utils.torch_utils import initialize_weights, de_parallel\n",
    "\n",
    "import torch_pruning as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c39e7624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def save_pruning_performance_graph(x, y1, y11, y2, y3, pruning_method=\"L2\"):\n",
    "    \"\"\"\n",
    "    Draw performance change graph\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : List\n",
    "        Parameter numbers of all pruning steps\n",
    "    y1 : List\n",
    "        mAPs after fine-tuning of all pruning steps\n",
    "    y11 : List\n",
    "        mAP50 after fine-tuning of all pruning steps\n",
    "    y2 : List\n",
    "        MACs of all pruning steps\n",
    "    y3 : List\n",
    "        mAPs after pruning (not fine-tuned) of all pruning steps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        plt.style.use(\"ggplot\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    x, y1, y11, y2, y3 = np.array(x), np.array(y1), np.array(y11), np.array(y2), np.array(y3)\n",
    "    y2_ratio = y2 / y2[0]\n",
    "\n",
    "    # create the figure and the axis object\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    # plot the pruned mAP and recovered mAP\n",
    "    ax.set_xlabel('Pruning Ratio')\n",
    "    ax.set_ylabel('mAP')\n",
    "    ax.plot(x, y1, label='recovered mAP')\n",
    "    ax.scatter(x, y1)\n",
    "    ax.plot(x, y11, color='tab:blue', label='recovered mAP50')\n",
    "    ax.scatter(x, y11, color='tab:blue')\n",
    "    ax.plot(x, y3, color='tab:gray', label='pruned mAP')\n",
    "    ax.scatter(x, y3, color='tab:gray')\n",
    "\n",
    "    # create a second axis that shares the same x-axis\n",
    "    ax2 = ax.twinx()\n",
    "\n",
    "    # plot the second set of data\n",
    "    ax2.set_ylabel('MACs')\n",
    "    ax2.plot(x, y2_ratio, color='tab:orange', label='MACs')\n",
    "    ax2.scatter(x, y2_ratio, color='tab:orange')\n",
    "\n",
    "    # add a legend\n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(lines + lines2, labels + labels2, loc='best')\n",
    "\n",
    "    ax.set_xlim(105, 20)\n",
    "    ax.set_ylim(0, max(y11) + 0.05)\n",
    "    ax2.set_ylim(0.05, 1.05)\n",
    "\n",
    "    # calculate the highest and lowest points for each set of data\n",
    "    max_y1_idx = np.argmax(y1)\n",
    "    min_y1_idx = np.argmin(y1)\n",
    "    max_y11_idx = np.argmax(y11)\n",
    "    min_y11_idx = np.argmin(y11)\n",
    "    max_y2_idx = np.argmax(y2)\n",
    "    min_y2_idx = np.argmin(y2)\n",
    "    max_y1 = y1[max_y1_idx]\n",
    "    min_y1 = y1[min_y1_idx]\n",
    "    max_y11 = y11[max_y11_idx]\n",
    "    min_y11 = y11[min_y11_idx]\n",
    "    max_y2 = y2_ratio[max_y2_idx]\n",
    "    min_y2 = y2_ratio[min_y2_idx]\n",
    "\n",
    "    # add text for the highest and lowest values near the points\n",
    "    ax.text(x[max_y1_idx], max_y1 - 0.05, f'max mAP = {max_y1:.2f}', fontsize=10)\n",
    "    ax.text(x[min_y1_idx], min_y1 + 0.02, f'min mAP = {min_y1:.2f}', fontsize=10)\n",
    "\n",
    "    ax.text(x[max_y11_idx], max_y11 + 0.02, f'max mAP50 = {max_y11:.2f}', fontsize=10)\n",
    "    ax.text(x[min_y11_idx], min_y11 + 0.02, f'min mAP50 = {min_y11:.2f}', fontsize=10)\n",
    "    \n",
    "    ax2.text(x[max_y2_idx], max_y2 - 0.05, f'max MACs = {max_y2 * y2[0] / 1e9:.2f}G', fontsize=10)\n",
    "    ax2.text(x[min_y2_idx], min_y2 + 0.02, f'min MACs = {min_y2 * y2[0] / 1e9:.2f}G', fontsize=10)\n",
    "\n",
    "    plt.title('Comparison of mAP / mAP50 and MACs with Pruning Ratio')\n",
    "    # Ensure the 'results' directory exists\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    plt.savefig(f'results/pruning_perf_change_{pruning_method}.png')\n",
    "\n",
    "#------------------------------------------------------------------------------------------------\n",
    "\n",
    "def infer_c3k2_shortcut(bottleneck):\n",
    "    \"\"\"\n",
    "    Infer whether to use shortcut and large-kernel flag from a child block.\n",
    "    Returns (shortcut: bool, is_cib: bool, lk: bool).\n",
    "    \"\"\"\n",
    "    # Bottleneck case: identical logic to C2f shortcut\n",
    "    if isinstance(bottleneck, Bottleneck):\n",
    "        c1 = bottleneck.cv1.conv.in_channels\n",
    "        c2 = bottleneck.cv2.conv.out_channels\n",
    "        add_flag = getattr(bottleneck, 'add', False)\n",
    "        return (c1 == c2 and add_flag), False, False\n",
    "    # C3k case: preserve shortcut and detect large-kernel usage\n",
    "    elif isinstance(bottleneck, C3k):\n",
    "        lk = any(isinstance(mod, RepVGGDW) for mod in getattr(bottleneck, 'm', []))\n",
    "        add_flag = getattr(bottleneck, 'add', False)\n",
    "        return add_flag, False, lk\n",
    "    # Fallback: treat as C3k-like\n",
    "    else:\n",
    "        lk = any(isinstance(mod, RepVGGDW) for mod in getattr(bottleneck, 'm', []))\n",
    "        add_flag = getattr(bottleneck, 'add', False)\n",
    "        return add_flag, False, lk\n",
    "\n",
    "class C2f_v2(nn.Module):\n",
    "    # CSP Bottleneck with 2 convolutions\n",
    "    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5,is_CIB = False, lk = False):  # ch_in, ch_out, number, shortcut, groups, expansion\n",
    "        super().__init__()\n",
    "        self.c = int(c2 * e)  # hidden channels\n",
    "        self.cv0 = Conv(c1, self.c, 1, 1)\n",
    "        self.cv1 = Conv(c1, self.c, 1, 1)\n",
    "        self.cv2 = Conv((2 + n) * self.c, c2, 1)  # optional act=FReLU(c2)\n",
    "        if not is_CIB:\n",
    "            self.m = nn.ModuleList(Bottleneck(self.c, self.c, shortcut, g, k=((3, 3), (3, 3)), e=1.0) for _ in range(n))\n",
    "        else:\n",
    "            self.m = nn.ModuleList(CIB(self.c, self.c, shortcut, e=1.0, lk=lk) for _ in range(n))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # y = list(self.cv1(x).chunk(2, 1))\n",
    "        y = [self.cv0(x), self.cv1(x)]\n",
    "        y.extend(m(y[-1]) for m in self.m)\n",
    "        return self.cv2(torch.cat(y, 1))\n",
    "\n",
    "class C3k2_v2(C2f_v2):\n",
    "    \"\"\"\n",
    "    Torch-pruning-compatible version of C3k2.\n",
    "    Splits the original cv1 into cv0/cv1 and rebuilds its module list.\n",
    "    \"\"\"\n",
    "    def __init__(self, c1, c2, n=1, c3k=False, e=0.5, g=1, shortcut=True):\n",
    "        # initialize using C2f_v2 scaffold\n",
    "        super().__init__(c1, c2, n, shortcut, g, e, is_CIB=False, lk=False)\n",
    "        # override the m list with C3k or Bottleneck blocks\n",
    "        self.m = nn.ModuleList(\n",
    "            C3k(self.c, self.c, 2, shortcut, g) if c3k else Bottleneck(self.c, self.c, shortcut, g)\n",
    "            for _ in range(n)\n",
    "        )\n",
    "\n",
    "\n",
    "def transfer_weights_c3k2(src: C3k2, dst: C3k2_v2):\n",
    "    \"\"\"\n",
    "    Transfer parameters and buffers from original C3k2 to C3k2_v2.\n",
    "    \"\"\"\n",
    "    # reuse final conv and module list pointers\n",
    "    dst.cv2 = src.cv2\n",
    "    dst.m = src.m\n",
    "\n",
    "    state_src = src.state_dict()\n",
    "    state_dst = dst.state_dict()\n",
    "\n",
    "    # split cv1 weights and BN buffers into cv0 and cv1\n",
    "    w_old = state_src['cv1.conv.weight']\n",
    "    half = w_old.shape[0] // 2\n",
    "    state_dst['cv0.conv.weight'] = w_old[:half]\n",
    "    state_dst['cv1.conv.weight'] = w_old[half:]\n",
    "    for bn in ['weight', 'bias', 'running_mean', 'running_var']:\n",
    "        v = state_src[f'cv1.bn.{bn}']\n",
    "        state_dst[f'cv0.bn.{bn}'] = v[:half]\n",
    "        state_dst[f'cv1.bn.{bn}'] = v[half:]\n",
    "\n",
    "    # copy all other parameters and buffers\n",
    "    for key, val in state_src.items():\n",
    "        if not key.startswith('cv1.'):\n",
    "            state_dst[key] = val\n",
    "\n",
    "    # copy non-callable attributes\n",
    "    for attr in dir(src):\n",
    "        if not callable(getattr(src, attr)) and '_' not in attr:\n",
    "            setattr(dst, attr, getattr(src, attr))\n",
    "\n",
    "    dst.load_state_dict(state_dst)\n",
    "\n",
    "\n",
    "def replace_c3k2_with_v2(module: nn.Module):\n",
    "    \"\"\"\n",
    "    Recursively replace all C3k2 instances in `module` with C3k2_v2.\n",
    "    \"\"\"\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, C3k2):\n",
    "            # infer flags from first inner block\n",
    "            c3k_flag = isinstance(child.m[0], C3k)\n",
    "            shortcut, is_cib, lk = infer_c3k2_shortcut(child.m[0])\n",
    "            # instantiate new block\n",
    "            v2 = C3k2_v2(\n",
    "                child.cv1.conv.in_channels,\n",
    "                child.cv2.conv.out_channels,\n",
    "                n=len(child.m),\n",
    "                c3k=c3k_flag,\n",
    "                e=child.c / child.cv2.conv.out_channels,\n",
    "                g=(child.m[0].cv2.conv.groups if not is_cib else child.cv2.conv.groups),\n",
    "                shortcut=shortcut,\n",
    "            )\n",
    "            # transfer weights and replace\n",
    "            transfer_weights_c3k2(child, v2)\n",
    "            setattr(module, name, v2)\n",
    "        else:\n",
    "            replace_c3k2_with_v2(child)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------\n",
    "\n",
    "def save_model_v2(self: BaseTrainer):\n",
    "    \"\"\"\n",
    "    Disabled half precision saving. originated from ultralytics/yolo/engine/trainer.py\n",
    "    \"\"\"\n",
    "    ckpt = {\n",
    "        'epoch': self.epoch,\n",
    "        'best_fitness': self.best_fitness,\n",
    "        'model': deepcopy(de_parallel(self.model)),\n",
    "        'ema': deepcopy(self.ema.ema),\n",
    "        'updates': self.ema.updates,\n",
    "        'optimizer': self.optimizer.state_dict(),\n",
    "        'train_args': vars(self.args),  # save as dict\n",
    "        'date': datetime.now().isoformat(),\n",
    "        'version': __version__}\n",
    "\n",
    "    # Save last, best and delete\n",
    "    torch.save(ckpt, self.last)\n",
    "    if self.best_fitness == self.fitness:\n",
    "        torch.save(ckpt, self.best)\n",
    "    if (self.epoch > 0) and (self.save_period > 0) and (self.epoch % self.save_period == 0):\n",
    "        torch.save(ckpt, self.wdir / f'epoch{self.epoch}.pt')\n",
    "    del ckpt\n",
    "\n",
    "\n",
    "def final_eval_v2(self: BaseTrainer):\n",
    "    \"\"\"\n",
    "    originated from ultralytics/yolo/engine/trainer.py\n",
    "    \"\"\"\n",
    "    for f in self.last, self.best:\n",
    "        if f.exists():\n",
    "            strip_optimizer_v2(f)  # strip optimizers\n",
    "            if f is self.best:\n",
    "                LOGGER.info(f'\\nValidating {f}...')\n",
    "                self.metrics = self.validator(model=f)\n",
    "                self.metrics.pop('fitness', None)\n",
    "                self.run_callbacks('on_fit_epoch_end')\n",
    "\n",
    "\n",
    "def strip_optimizer_v2(f: Union[str, Path] = 'best.pt', s: str = '') -> None:\n",
    "    \"\"\"\n",
    "    Disabled half precision saving. originated from ultralytics/yolo/utils/torch_utils.py\n",
    "    \"\"\"\n",
    "    x = torch.load(f, map_location=torch.device('cpu'))\n",
    "    args = {**DEFAULT_CFG_DICT, **x['train_args']}  # combine model args with default args, preferring model args\n",
    "    if x.get('ema'):\n",
    "        x['model'] = x['ema']  # replace model with ema\n",
    "    for k in 'optimizer', 'ema', 'updates':  # keys\n",
    "        x[k] = None\n",
    "    for p in x['model'].parameters():\n",
    "        p.requires_grad = False\n",
    "    x['train_args'] = {k: v for k, v in args.items() if k in DEFAULT_CFG_KEYS}  # strip non-default keys\n",
    "    # x['model'].args = x['train_args']\n",
    "    torch.save(x, s or f)\n",
    "    mb = os.path.getsize(s or f) / 1E6  # filesize\n",
    "    LOGGER.info(f\"Optimizer stripped from {f},{f' saved as {s},' if s else ''} {mb:.1f}MB\")\n",
    "\n",
    "\n",
    "def train_v2(self: YOLO, **train_params):\n",
    "    \"\"\"\n",
    "    Disabled loading new model when pruning flag is set. originated from ultralytics/yolo/engine/model.py\n",
    "    \"\"\"\n",
    "    \n",
    "    self._check_is_pytorch_model()\n",
    "    # Override Training Parameters with provided ones \n",
    "    overrides = self.overrides.copy()\n",
    "    overrides.update(train_params)\n",
    "    if train_params.get('cfg'):\n",
    "        overrides = yaml_load(check_yaml(train_params['cfg']))\n",
    "    overrides['mode'] = 'train'\n",
    "    if not overrides.get('data'):\n",
    "        raise AttributeError(\"Dataset required but missing, i.e. pass 'data=coco128.yaml'\")\n",
    "    if overrides.get('resume'):\n",
    "        overrides['resume'] = self.ckpt_path\n",
    "\n",
    "    # Initialize trainer\n",
    "    self.task = \"detect\"\n",
    "    self.callbacks = []\n",
    "    self.trainer = self.task_map[self.task]['trainer'](overrides=overrides, _callbacks=self.callbacks)\n",
    "\n",
    "    self.trainer.verbose = False  \n",
    "\n",
    "    # pruning mode\n",
    "    self.trainer.pruning = True\n",
    "    self.trainer.model = self.model\n",
    "    \n",
    "    # replace some functions to disable half precision saving\n",
    "    self.trainer.save_model = save_model_v2.__get__(self.trainer)\n",
    "    self.trainer.final_eval = final_eval_v2.__get__(self.trainer)\n",
    "\n",
    "    self.trainer.train()\n",
    "    # Update model and cfg after training\n",
    "    if RANK in (-1, 0):\n",
    "        self.model, _ = attempt_load_one_weight(str(self.trainer.best))\n",
    "        self.overrides = self.model.args\n",
    "        self.metrics = getattr(self.trainer.validator, 'metrics', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f969ecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model(model, target_prune_rate=0.8, iterations=24, map_threshold=0.10, train_params=\"finetune.yaml\"):\n",
    "    \"\"\"\n",
    "    Apply structured channel pruning to the model.\n",
    "    :param model: The YOLO model to prune.\n",
    "    :param amount: The fraction of channels to prune.\n",
    "    \"\"\"\n",
    "    # set training to train_v2 and load the training parameters\n",
    "    model.__setattr__(\"train_v2\", train_v2.__get__(model))\n",
    "    train_params = yaml_load(check_yaml(train_params))\n",
    "    # Set the model to training mode\n",
    "    model.model.train()  \n",
    "\n",
    "    # change c2f implementation to be compatible with the Graph pruner\n",
    "    replace_c3k2_with_v2(model.model) # avoids shared references\n",
    "    initialize_weights(model.model)\n",
    "\n",
    "    # unfreeze all the layers, making them trainable\n",
    "    for name, param in model.model.named_parameters():\n",
    "        param.requires_grad = True # set all to True\n",
    "    # dummy input to trace  the model's computation graph\n",
    "    example_inputs = torch.randn(1, 3, train_params[\"imgsz\"], train_params[\"imgsz\"]).to(model.device)\n",
    "    \n",
    "    # Initialize metrics list to plot and logging purpose\n",
    "    macs_list, nparams_list, map_list, map50_list, pruned_map_list = [], [], [], [], []\n",
    "    \n",
    "    # Get the initial number of FLOPs and parameters\n",
    "    base_macs, base_nparams = tp.utils.count_ops_and_params(model.model, example_inputs)\n",
    "    \n",
    "    # Do validation before pruning model for baseline metrics\n",
    "    train_params['name'] = \"baseline_val\"\n",
    "    train_params['batch'] = 1\n",
    "    validation_model = deepcopy(model)\n",
    "    results = validation_model.val(**train_params, verbose=False)\n",
    "    # Save the metrics\n",
    "    init_map = results.box.map\n",
    "    init_map50 = results.box.map50\n",
    "    \n",
    "    # add the initial metrics to the lists\n",
    "    macs_list.append(base_macs)\n",
    "    nparams_list.append(100) # as % of parameters\n",
    "    map_list.append(init_map)\n",
    "    map50_list.append(init_map50)\n",
    "    pruned_map_list.append(init_map)\n",
    "    print(f\"Before Pruning: MACs={base_macs / 1e9: .5f} G, #Params={base_nparams / 1e6: .5f} M, mAP={init_map: .5f}\")\n",
    "    # prune same ratio of filter based on initial size\n",
    "    prune_per_step = 1 - (1 - target_prune_rate)**(1 / iterations)\n",
    "    print(f\"\\n prune_per_step: {target_prune_rate / iterations:.3f} - iterations: {iterations} - map_threshold: {map_threshold:.3f}\")\n",
    "\n",
    "\n",
    "    # Iterate and prune based on the selected iterative steps\n",
    "    print(f\"\\n -------------- MODEL PRUNING ----------------\")\n",
    "    for i in range(iterations):\n",
    "        \n",
    "        # Reset the loss function and unfreeze the layers\n",
    "        model.model.criterion = None \n",
    "        model.model.train()\n",
    "        for name, param in model.model.named_parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        # Filter out the layers that don't want to be pruned\n",
    "        ignored_layers = []\n",
    "        unwrapped_parameters = []\n",
    "        for m in model.model.modules():\n",
    "            if isinstance(m, (Detect,Attention,Concat)):\n",
    "                ignored_layers.append(m)\n",
    "        \n",
    "        example_inputs = example_inputs.to(model.device) # move dummy input to device\n",
    "        \n",
    "        # Initialize the pruner instance (structured pruning on channels or filters)\n",
    "        pruner = tp.pruner.GroupNormPruner(\n",
    "            model.model,\n",
    "            example_inputs,\n",
    "            importance=tp.importance.GroupMagnitudeImportance(p=2),  # L2 norm pruning\n",
    "            iterative_steps=1,\n",
    "            pruning_ratio=prune_per_step,\n",
    "            ignored_layers=ignored_layers,\n",
    "            unwrapped_parameters=unwrapped_parameters\n",
    "        )\n",
    "                \n",
    "        # prune the model\n",
    "        pruner.step()\n",
    "\n",
    "        print(f\"\\n--------------- STEP {i + 1} OF {iterations} -----------------\")\n",
    "        print(f\"\\n------------ PRUNED RATIO : {1- (1 - prune_per_step)**(i+1):.3f} -----------\")\n",
    "        \n",
    "        \n",
    "        # Validation after the model has been pruned - before fine-tuning\n",
    "        train_params['name'] = f\"step_{i}_pre_val\" \n",
    "        train_params['batch'] = 1\n",
    "        validation_model.model = deepcopy(model.model)\n",
    "        metric = validation_model.val(**train_params, verbose=False)\n",
    "        pruned_map = metric.box.map\n",
    "        pruned_macs, pruned_nparams = tp.utils.count_ops_and_params(pruner.model, example_inputs.to(model.device))\n",
    "        current_speed_up = float(macs_list[0]) / pruned_macs\n",
    "        \n",
    "        print(f\"After pruning iter {i + 1}: MACs={pruned_macs / 1e9} G, #Params={pruned_nparams / 1e6} M, \"\n",
    "            f\"mAP={pruned_map}, speed up={current_speed_up},  pruned_param_ratio={pruned_nparams / base_nparams * 100:.3f} %\")\n",
    "        \n",
    "        # fine-tuning the pruned model\n",
    "        model.model.train()\n",
    "        for name, param in model.model.named_parameters():\n",
    "            param.requires_grad = True\n",
    "        train_params['name'] = f\"step_{i}_finetune\"\n",
    "        train_params['batch'] = 150\n",
    "        model.train_v2(**train_params)\n",
    "\n",
    "        # post fine-tuning validation\n",
    "        train_params['name'] = f\"step_{i}_post_val\"\n",
    "        train_params['batch'] = 1\n",
    "        validation_model = YOLO(model.trainer.best)\n",
    "        metric = validation_model.val(**train_params,verbose=False)\n",
    "        current_map = metric.box.map\n",
    "        current_map50 = metric.box.map50\n",
    "        \n",
    "        print(f\"\\nAfter fine tuning mAP={current_map} - mAP50={current_map50} - pruned_param_ratio={pruned_nparams / base_nparams * 100:.3f}% \\n\")\n",
    "        \n",
    "        macs_list.append(pruned_macs)\n",
    "        nparams_list.append(pruned_nparams / base_nparams * 100)\n",
    "        pruned_map_list.append(pruned_map)\n",
    "        map_list.append(current_map)\n",
    "        map50_list.append(current_map50)\n",
    "        \n",
    "        # remove pruner after single iteration\n",
    "        del pruner\n",
    "        \n",
    "        save_pruning_performance_graph(nparams_list, map_list, map50_list, macs_list, pruned_map_list, \"L2 norm\")\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Stop if the metrics drop is greater than the max_map_drop parameter\n",
    "        if init_map - current_map > map_threshold:\n",
    "            print(\"Pruning early stop\")\n",
    "            break\n",
    "\n",
    "    # --- End Iterative Pruning Loop ---\n",
    "    # Combine all metrics into a dictionary\n",
    "    metrics = {\n",
    "        \"macs_list\": macs_list,\n",
    "        \"nparams_list\": nparams_list,\n",
    "        \"pruned_map_list\": pruned_map_list,\n",
    "        \"map_list\": map_list,\n",
    "        \"map50_list\": map50_list\n",
    "    }\n",
    "    with open(\"results/pruning_metrics.json\", 'w') as f:\n",
    "        json.dump(metrics, f)\n",
    "    \n",
    "    model.save(\"models\\\\pruned_v4.pt\") # save the pruned model\n",
    "    print(\"model saved to pt\")\n",
    "    # Export final model\n",
    "    exported = model.export(format=\"onnx\", simplify = True)\n",
    "    print(f\"Final pruned model exported to onnx, {exported}.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f5f36b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1541/1541 [00:26<00:00, 58.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Pruning: MACs= 0.39073 G, #Params= 2.59023 M, mAP= 0.33323\n",
      "\n",
      " prune_per_step: 0.080 - iterations: 10 - map_threshold: 0.100\n",
      "\n",
      " -------------- MODEL PRUNING ----------------\n",
      "\n",
      "--------------- STEP 1 OF 10 -----------------\n",
      "\n",
      "------------ PRUNED RATIO : 0.080 -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1541/1541 [00:24<00:00, 63.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pruning iter 1: MACs=0.344006068 G, #Params=2.277913 M, mAP=0.00022614478516735998, speed up=1.1358287377651721,  pruned_param_ratio=87.942 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\train.cache... 6164 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6164/6164 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "       1/10      3.09G      1.742      1.373      1.023        148        224: 100%|██████████| 42/42 [00:26<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:06<00:00,  1.11s/it]\n",
      "       2/10      3.05G      1.432      1.085      0.962        144        224: 100%|██████████| 42/42 [00:20<00:00,  2.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n",
      "       3/10      3.29G      1.468      1.102     0.9679        105        224: 100%|██████████| 42/42 [00:21<00:00,  1.93it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:07<00:00,  1.17s/it]\n",
      "       4/10      3.67G      1.456      1.094     0.9735         98        224: 100%|██████████| 42/42 [00:21<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:07<00:00,  1.18s/it]\n",
      "       5/10      3.21G      1.414      1.034     0.9609        116        224: 100%|██████████| 42/42 [00:21<00:00,  2.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:07<00:00,  1.21s/it]\n",
      "       6/10      3.36G      1.363     0.9825      0.948         99        224: 100%|██████████| 42/42 [00:20<00:00,  2.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:07<00:00,  1.22s/it]\n",
      "       7/10      3.03G      1.323     0.9376     0.9414         57        224: 100%|██████████| 42/42 [00:21<00:00,  1.95it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n",
      "       8/10      3.32G      1.298      0.915     0.9373         81        224: 100%|██████████| 42/42 [00:20<00:00,  2.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:07<00:00,  1.22s/it]\n",
      "       9/10      3.75G       1.27     0.8812     0.9274         84        224: 100%|██████████| 42/42 [00:20<00:00,  2.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n",
      "      10/10      3.29G      1.251     0.8488     0.9221        142        224: 100%|██████████| 42/42 [00:21<00:00,  1.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:06<00:00,  1.06s/it]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1541/1541 [00:29<00:00, 51.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After fine tuning mAP=0.2995117615750687 - mAP50=0.4785378106658205 - pruned_param_ratio=87.942% \n",
      "\n",
      "\n",
      "--------------- STEP 2 OF 10 -----------------\n",
      "\n",
      "------------ PRUNED RATIO : 0.154 -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1541/1541 [00:25<00:00, 59.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pruning iter 2: MACs=0.304917249 G, #Params=2.020094 M, mAP=0.0, speed up=1.2814361249861597,  pruned_param_ratio=77.989 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\train.cache... 6164 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6164/6164 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "       1/10         3G      1.671      1.189      1.008        148        224: 100%|██████████| 42/42 [00:35<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:10<00:00,  1.82s/it]\n",
      "       2/10      2.92G      1.406     0.9925     0.9535        144        224: 100%|██████████| 42/42 [00:22<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.44s/it]\n",
      "       3/10      2.93G      1.407     0.9969     0.9513        105        224: 100%|██████████| 42/42 [00:23<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.38s/it]\n",
      "       4/10      3.31G      1.395     0.9995     0.9588         98        224: 100%|██████████| 42/42 [00:22<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.37s/it]\n",
      "       5/10      3.08G      1.358     0.9674     0.9463        116        224: 100%|██████████| 42/42 [00:22<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.37s/it]\n",
      "       6/10      3.17G      1.335     0.9412     0.9396         99        224: 100%|██████████| 42/42 [00:23<00:00,  1.76it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.38s/it]\n",
      "       7/10       2.9G      1.304     0.9051     0.9365         57        224: 100%|██████████| 42/42 [00:24<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.39s/it]\n",
      "       8/10      3.19G      1.284     0.8853     0.9335         81        224: 100%|██████████| 42/42 [00:22<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.52s/it]\n",
      "       9/10      3.44G      1.267     0.8682     0.9246         84        224: 100%|██████████| 42/42 [00:23<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.49s/it]\n",
      "      10/10      3.16G      1.249     0.8416     0.9189        142        224: 100%|██████████| 42/42 [00:22<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.41s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:07<00:00,  1.17s/it]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1541/1541 [00:30<00:00, 50.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After fine tuning mAP=0.28785134388609934 - mAP50=0.4634141190397327 - pruned_param_ratio=77.989% \n",
      "\n",
      "\n",
      "--------------- STEP 3 OF 10 -----------------\n",
      "\n",
      "------------ PRUNED RATIO : 0.221 -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1541/1541 [00:27<00:00, 55.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pruning iter 3: MACs=0.273037016 G, #Params=1.795642 M, mAP=0.0020209574659946095, speed up=1.431058629793991,  pruned_param_ratio=69.324 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\train.cache... 6164 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6164/6164 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "       1/10      2.87G      1.704      1.232       1.01        148        224: 100%|██████████| 42/42 [00:30<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:07<00:00,  1.22s/it]\n",
      "       2/10      2.81G       1.38     0.9602     0.9477        144        224: 100%|██████████| 42/42 [00:21<00:00,  1.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n",
      "       3/10      2.83G        1.4     0.9679     0.9453        105        224: 100%|██████████| 42/42 [00:22<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n",
      "       4/10       3.2G      1.388     0.9777     0.9529         98        224: 100%|██████████| 42/42 [00:22<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n",
      "       5/10      2.97G      1.357     0.9464     0.9399        116        224: 100%|██████████| 42/42 [00:22<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n",
      "       6/10      3.06G      1.327     0.9157     0.9342         99        224: 100%|██████████| 42/42 [00:22<00:00,  1.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n",
      "       7/10      2.79G      1.306     0.8908     0.9325         57        224: 100%|██████████| 42/42 [00:22<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:07<00:00,  1.31s/it]\n",
      "       8/10      3.04G      1.278     0.8724     0.9281         81        224: 100%|██████████| 42/42 [00:22<00:00,  1.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:07<00:00,  1.31s/it]\n",
      "       9/10      3.34G      1.274     0.8564     0.9233         84        224: 100%|██████████| 42/42 [00:24<00:00,  1.73it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.48s/it]\n",
      "      10/10      3.05G       1.26     0.8408     0.9187        142        224: 100%|██████████| 42/42 [00:23<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:06<00:00,  1.14s/it]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1541/1541 [00:31<00:00, 49.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After fine tuning mAP=0.27989210626507427 - mAP50=0.4593809560834491 - pruned_param_ratio=69.324% \n",
      "\n",
      "\n",
      "--------------- STEP 4 OF 10 -----------------\n",
      "\n",
      "------------ PRUNED RATIO : 0.284 -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1541/1541 [00:30<00:00, 51.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pruning iter 4: MACs=0.24883768 G, #Params=1.61883 M, mAP=0.017643964551741827, speed up=1.57022834323162,  pruned_param_ratio=62.498 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\train.cache... 6164 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6164/6164 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "       1/10      2.78G      1.728      1.202       1.02        148        224: 100%|██████████| 42/42 [00:31<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.52s/it]\n",
      "       2/10      2.72G      1.403     0.9629     0.9496        144        224: 100%|██████████| 42/42 [00:22<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.58s/it]\n",
      "       3/10      2.73G      1.402     0.9664     0.9443        105        224: 100%|██████████| 42/42 [00:23<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.50s/it]\n",
      "       4/10      3.11G      1.387     0.9619     0.9513         98        224: 100%|██████████| 42/42 [00:23<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.50s/it]\n",
      "       5/10      2.87G      1.355     0.9344     0.9366        116        224: 100%|██████████| 42/42 [00:23<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.61s/it]\n",
      "       6/10      2.84G      1.335     0.9175     0.9338         99        224: 100%|██████████| 42/42 [00:22<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.60s/it]\n",
      "       7/10      2.69G      1.314      0.887      0.933         57        224: 100%|██████████| 42/42 [00:22<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.55s/it]\n",
      "       8/10      2.94G      1.293     0.8685     0.9295         81        224: 100%|██████████| 42/42 [00:22<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.55s/it]\n",
      "       9/10      3.33G      1.279     0.8578     0.9236         84        224: 100%|██████████| 42/42 [00:23<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.59s/it]\n",
      "      10/10      2.95G      1.268     0.8387     0.9203        142        224: 100%|██████████| 42/42 [00:23<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.57s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:07<00:00,  1.19s/it]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1541/1541 [00:29<00:00, 52.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After fine tuning mAP=0.27494909655739874 - mAP50=0.4494665578385576 - pruned_param_ratio=62.498% \n",
      "\n",
      "\n",
      "--------------- STEP 5 OF 10 -----------------\n",
      "\n",
      "------------ PRUNED RATIO : 0.341 -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1541/1541 [00:26<00:00, 57.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pruning iter 5: MACs=0.226677136 G, #Params=1.457006 M, mAP=0.010907219290922018, speed up=1.723737933586738,  pruned_param_ratio=56.250 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\train.cache... 6164 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6164/6164 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "       1/10      2.67G       1.86      1.311      1.056        148        224: 100%|██████████| 42/42 [00:35<00:00,  1.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:11<00:00,  1.85s/it]\n",
      "       2/10      2.62G      1.439     0.9656     0.9556        144        224: 100%|██████████| 42/42 [00:23<00:00,  1.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.58s/it]\n",
      "       3/10      2.63G      1.425     0.9714     0.9456        105        224: 100%|██████████| 42/42 [00:27<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.57s/it]\n",
      "       4/10      3.01G      1.403     0.9654     0.9537         98        224: 100%|██████████| 42/42 [00:22<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:10<00:00,  1.76s/it]\n",
      "       5/10      2.78G      1.372     0.9392     0.9375        116        224: 100%|██████████| 42/42 [00:22<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.48s/it]\n",
      "       6/10      2.74G       1.35     0.9138     0.9365         99        224: 100%|██████████| 42/42 [00:22<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.52s/it]\n",
      "       7/10       2.6G      1.322      0.896     0.9338         57        224: 100%|██████████| 42/42 [00:22<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.48s/it]\n",
      "       8/10      2.84G      1.309     0.8799     0.9314         81        224: 100%|██████████| 42/42 [00:22<00:00,  1.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.51s/it]\n",
      "       9/10      3.23G      1.298     0.8667     0.9263         84        224: 100%|██████████| 42/42 [00:22<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.49s/it]\n",
      "      10/10      2.86G      1.279     0.8431     0.9212        142        224: 100%|██████████| 42/42 [00:22<00:00,  1.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:06<00:00,  1.15s/it]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1541/1541 [00:29<00:00, 52.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After fine tuning mAP=0.26666149957322516 - mAP50=0.4443502383290345 - pruned_param_ratio=56.250% \n",
      "\n",
      "\n",
      "--------------- STEP 6 OF 10 -----------------\n",
      "\n",
      "------------ PRUNED RATIO : 0.394 -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1541/1541 [00:27<00:00, 55.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pruning iter 6: MACs=0.207251478 G, #Params=1.317277 M, mAP=0.019379996013155168, speed up=1.885303698533817,  pruned_param_ratio=50.856 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\train.cache... 6164 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6164/6164 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "       1/10      2.58G      1.687      1.141      1.005        148        224: 100%|██████████| 42/42 [00:30<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.51s/it]\n",
      "       2/10      2.51G      1.424     0.9572     0.9521        144        224: 100%|██████████| 42/42 [00:22<00:00,  1.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.53s/it]\n",
      "       3/10      2.64G      1.416      0.951     0.9457        105        224: 100%|██████████| 42/42 [00:22<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.48s/it]\n",
      "       4/10      3.19G      1.406     0.9484     0.9518         98        224: 100%|██████████| 42/42 [00:22<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.46s/it]\n",
      "       5/10      2.66G      1.377     0.9313     0.9381        116        224: 100%|██████████| 42/42 [00:22<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.47s/it]\n",
      "       6/10      2.77G      1.339     0.9062     0.9329         99        224: 100%|██████████| 42/42 [00:22<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.56s/it]\n",
      "       7/10      2.48G      1.339     0.8944     0.9352         57        224: 100%|██████████| 42/42 [00:22<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.53s/it]\n",
      "       8/10      2.73G      1.309     0.8735      0.929         81        224: 100%|██████████| 42/42 [00:22<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.55s/it]\n",
      "       9/10      3.24G      1.304     0.8655      0.927         84        224: 100%|██████████| 42/42 [00:22<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.54s/it]\n",
      "      10/10      2.75G      1.296      0.853     0.9249        142        224: 100%|██████████| 42/42 [00:22<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.50s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:06<00:00,  1.14s/it]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1541/1541 [00:29<00:00, 53.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After fine tuning mAP=0.25935938116935775 - mAP50=0.4427738413379693 - pruned_param_ratio=50.856% \n",
      "\n",
      "\n",
      "--------------- STEP 7 OF 10 -----------------\n",
      "\n",
      "------------ PRUNED RATIO : 0.442 -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1541/1541 [00:27<00:00, 56.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pruning iter 7: MACs=0.191712843 G, #Params=1.206266 M, mAP=0.02103863538330962, speed up=2.0381106027414138,  pruned_param_ratio=46.570 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\train.cache... 6164 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6164/6164 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "       1/10       2.5G      1.714      1.164      1.013        148        224: 100%|██████████| 42/42 [00:31<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:10<00:00,  1.75s/it]\n",
      "       2/10      2.44G      1.426     0.9537     0.9538        144        224: 100%|██████████| 42/42 [00:22<00:00,  1.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.59s/it]\n",
      "       3/10      3.99G      1.418     0.9454     0.9455        105        224: 100%|██████████| 42/42 [00:23<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.55s/it]\n",
      "       4/10      3.99G      1.405     0.9477     0.9534         98        224: 100%|██████████| 42/42 [00:23<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.57s/it]\n",
      "       5/10      3.99G      1.373      0.921      0.939        116        224: 100%|██████████| 42/42 [00:22<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.58s/it]\n",
      "       6/10      3.99G      1.347     0.9011     0.9336         99        224: 100%|██████████| 42/42 [00:22<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.65s/it]\n",
      "       7/10      3.99G       1.34     0.8953     0.9362         57        224: 100%|██████████| 42/42 [00:22<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.59s/it]\n",
      "       8/10      3.99G      1.319      0.878     0.9322         81        224: 100%|██████████| 42/42 [00:22<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.61s/it]\n",
      "       9/10      3.99G      1.312     0.8697     0.9288         84        224: 100%|██████████| 42/42 [00:22<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.58s/it]\n",
      "      10/10      3.99G      1.303     0.8609      0.927        142        224: 100%|██████████| 42/42 [00:22<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.59s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1541/1541 [00:29<00:00, 52.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After fine tuning mAP=0.256220691611575 - mAP50=0.4467112952466792 - pruned_param_ratio=46.570% \n",
      "\n",
      "\n",
      "--------------- STEP 8 OF 10 -----------------\n",
      "\n",
      "------------ PRUNED RATIO : 0.487 -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1541/1541 [00:26<00:00, 57.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pruning iter 8: MACs=0.177976869 G, #Params=1.105166 M, mAP=0.003046063706501913, speed up=2.1954087640456246,  pruned_param_ratio=42.667 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\train.cache... 6164 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6164/6164 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "       1/10      2.44G      1.899      1.355      1.057        148        224: 100%|██████████| 42/42 [00:30<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:10<00:00,  1.76s/it]\n",
      "       2/10         4G      1.504      1.012     0.9686        144        224: 100%|██████████| 42/42 [00:22<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.49s/it]\n",
      "       3/10         4G      1.475     0.9917     0.9563        105        224: 100%|██████████| 42/42 [00:23<00:00,  1.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.49s/it]\n",
      "       4/10         4G      1.441     0.9718     0.9577         98        224: 100%|██████████| 42/42 [00:23<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.58s/it]\n",
      "       5/10         4G      1.419     0.9588     0.9504        116        224: 100%|██████████| 42/42 [00:22<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.66s/it]\n",
      "       6/10      2.76G      1.389      0.936     0.9432         99        224: 100%|██████████| 42/42 [00:22<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.65s/it]\n",
      "       7/10      2.35G      1.371     0.9207     0.9436         57        224: 100%|██████████| 42/42 [00:22<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.50s/it]\n",
      "       8/10       3.9G      1.352     0.8992     0.9386         81        224: 100%|██████████| 42/42 [00:22<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.57s/it]\n",
      "       9/10       3.9G      1.343     0.8899     0.9353         84        224: 100%|██████████| 42/42 [00:22<00:00,  1.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.60s/it]\n",
      "      10/10       3.9G      1.337     0.8931     0.9335        142        224: 100%|██████████| 42/42 [00:22<00:00,  1.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.63s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:06<00:00,  1.15s/it]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1541/1541 [00:28<00:00, 54.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After fine tuning mAP=0.26326731083421534 - mAP50=0.44430825268295576 - pruned_param_ratio=42.667% \n",
      "\n",
      "\n",
      "--------------- STEP 9 OF 10 -----------------\n",
      "\n",
      "------------ PRUNED RATIO : 0.528 -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1541/1541 [00:26<00:00, 57.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pruning iter 9: MACs=0.16556365 G, #Params=1.013435 M, mAP=0.012569268391926836, speed up=2.3600106545126303,  pruned_param_ratio=39.125 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\train.cache... 6164 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6164/6164 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "       1/10      2.35G      2.085      1.553      1.118        148        224: 100%|██████████| 42/42 [00:30<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.52s/it]\n",
      "       2/10      3.91G      1.563      1.087     0.9851        144        224: 100%|██████████| 42/42 [00:22<00:00,  1.89it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.47s/it]\n",
      "       3/10      3.91G      1.516      1.044     0.9665        105        224: 100%|██████████| 42/42 [00:22<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.47s/it]\n",
      "       4/10      3.91G      1.474      1.014     0.9645         98        224: 100%|██████████| 42/42 [00:22<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.44s/it]\n",
      "       5/10      3.91G      1.443      1.004     0.9547        116        224: 100%|██████████| 42/42 [00:23<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.47s/it]\n",
      "       6/10      3.91G      1.419     0.9738     0.9486         99        224: 100%|██████████| 42/42 [00:22<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.48s/it]\n",
      "       7/10      3.91G      1.401     0.9675     0.9488         57        224: 100%|██████████| 42/42 [00:22<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.49s/it]\n",
      "       8/10      3.91G      1.376     0.9331     0.9459         81        224: 100%|██████████| 42/42 [00:22<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.67s/it]\n",
      "       9/10      3.91G      1.367     0.9211     0.9399         84        224: 100%|██████████| 42/42 [00:22<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:10<00:00,  1.82s/it]\n",
      "      10/10      3.91G       1.36     0.9146     0.9377        142        224: 100%|██████████| 42/42 [00:22<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:10<00:00,  1.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.40s/it]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1541/1541 [00:29<00:00, 53.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After fine tuning mAP=0.2595464624268021 - mAP50=0.439609614621915 - pruned_param_ratio=39.125% \n",
      "\n",
      "\n",
      "--------------- STEP 10 OF 10 -----------------\n",
      "\n",
      "------------ PRUNED RATIO : 0.566 -----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1541/1541 [00:27<00:00, 56.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pruning iter 10: MACs=0.156032268 G, #Params=0.93901 M, mAP=0.02189366635716004, speed up=2.5041741878673456,  pruned_param_ratio=36.252 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\train.cache... 6164 images, 0 backgrounds, 0 corrupt: 100%|██████████| 6164/6164 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "       1/10      2.29G      1.976        1.5      1.058        148        224: 100%|██████████| 42/42 [00:30<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.49s/it]\n",
      "       2/10      3.85G      1.565      1.108     0.9786        144        224: 100%|██████████| 42/42 [00:22<00:00,  1.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.58s/it]\n",
      "       3/10      3.85G      1.523      1.071     0.9675        105        224: 100%|██████████| 42/42 [00:23<00:00,  1.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.55s/it]\n",
      "       4/10      3.85G       1.49      1.056     0.9671         98        224: 100%|██████████| 42/42 [00:22<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.65s/it]\n",
      "       5/10      3.85G      1.466      1.033     0.9581        116        224: 100%|██████████| 42/42 [00:22<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.65s/it]\n",
      "       6/10      3.85G       1.44      1.004     0.9517         99        224: 100%|██████████| 42/42 [00:22<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.52s/it]\n",
      "       7/10      3.85G       1.42     0.9923     0.9513         57        224: 100%|██████████| 42/42 [00:22<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.52s/it]\n",
      "       8/10      3.85G        1.4     0.9686     0.9486         81        224: 100%|██████████| 42/42 [00:22<00:00,  1.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.55s/it]\n",
      "       9/10      3.85G      1.383     0.9593     0.9422         84        224: 100%|██████████| 42/42 [00:22<00:00,  1.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:09<00:00,  1.52s/it]\n",
      "      10/10      3.85G      1.386     0.9467     0.9424        142        224: 100%|██████████| 42/42 [00:22<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:10<00:00,  1.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:08<00:00,  1.34s/it]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\yurim\\Documents\\University\\UM\\Year_3\\Bachelor_Thesis\\Weed_Detection_eSys\\datasets\\yolo_CropOrWeed2\\labels\\val.cache... 1541 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1541/1541 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1541/1541 [00:25<00:00, 59.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After fine tuning mAP=0.24615981406721527 - mAP50=0.4188011910632645 - pruned_param_ratio=36.252% \n",
      "\n",
      "model saved to pt\n",
      "Final pruned model exported to onnx, yolo\\runs\\detect\\step_9_finetune\\weights\\best.onnx.\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"models\\\\v4_augmented.pt\")\n",
    "logging.getLogger('ultralytics').setLevel(logging.WARNING)\n",
    "\n",
    "prune_model(model, target_prune_rate=0.8, iterations=10, map_threshold=0.10, train_params=\"finetune.yaml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
